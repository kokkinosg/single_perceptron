{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80863b31",
   "metadata": {},
   "source": [
    "# [INSERT PROJECT TITLE]\n",
    "\n",
    "[INSERT ROJECT DESCRIPTION]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7aca32",
   "metadata": {},
   "source": [
    "## 1.0: Data ingestion\n",
    "\n",
    "Load the MNIST handwritten digits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4d9b4",
   "metadata": {},
   "source": [
    "### 1.1: Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9384799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. training data = 60000\n",
      "No. test data = 10000\n",
      "Each training/test data is an image of 28 x 28 bits.\n",
      "Y data correspond to a digit which is depicted in a corresponding 28 x 28 image. For example, for 2nd image, y = 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. training data = {x_train.shape[0]}\")\n",
    "print(f\"No. test data = {x_test.shape[0]}\")\n",
    "print(f\"Each training/test data is an image of {x_train.shape[1]} x {x_train.shape[2]} bits.\")\n",
    "print(f\"Y data correspond to a digit which is depicted in a corresponding 28 x 28 image. For example, for 2nd image, y = {y_train[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d43926",
   "metadata": {},
   "source": [
    "## 2.0: Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6d6dd",
   "metadata": {},
   "source": [
    "### 2.1: Normalise pixel values\n",
    "\n",
    "Each pixel is [0,255]. We need to make it symmetric around 0 and make the max and min smaller so our MLP trains more effectively. \n",
    "\n",
    "This means we have to convert them from [0,255] to [-1.1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d887f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 127.5 - 1, x_test / 127.5 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c83e2",
   "metadata": {},
   "source": [
    "### 2.2: Flatten the input data\n",
    "\n",
    "A Multi-Layer Perceptron (MLP) does not explicitly model spatial relationships in images. Instead, it expects the input to be a one-dimensional feature vector. Therefore, each image must be flattened before being passed to the network. This means that instead of x_train.shape = (60000,28,28), it should be (60000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f46f4c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After flattening, the x_train shape = (60000, 784)\n",
      "After flattening, the x_test shape = (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find the total number of pixels \n",
    "nb_features = np.prod(x_train.shape[1:])\n",
    "\n",
    "# Change the shape from (n_train,28,28) to (n_train,784)\n",
    "n_train = x_train.shape[0]\n",
    "x_train.resize((n_train, nb_features))\n",
    "print(f\"After flattening, the x_train shape = {x_train.shape}\")\n",
    "\n",
    "# Change shape of test data \n",
    "n_test = x_test.shape[0]\n",
    "x_test.resize((n_test, nb_features))\n",
    "print(f\"After flattening, the x_test shape = {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84014c",
   "metadata": {},
   "source": [
    "## 3.0 PCA - NOT YET IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff7163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3ea5d04",
   "metadata": {},
   "source": [
    "## 4.0 Perceptrons\n",
    "\n",
    "We will implement an iterative algorithm for training the single layer perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440c067",
   "metadata": {},
   "source": [
    "### 4.1 Filter data for binary classifier\n",
    "\n",
    "As we are dealing with a binary classification problem, we will pick data points corresponding to classes 0 and 1 (handwritten digits). In  addition, we choose our binary labels to be -1 and 1, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c9b2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a condition mask. If the label is 1 or 0, it outputs True, otherwise False. \n",
    "cond = (y_train == 0) | (y_train == 1) \n",
    "\n",
    "# Extract all elements from x_train and y_train where the corresponding element from y_train satsifies the condition.\n",
    "binary_x_train = x_train[cond,:]\n",
    "binary_y_train = y_train[cond] # y_train is 1D\n",
    "\n",
    "# COnvert the labels to float. By defualt its is uint8 which doesn't accept negative numbers.\n",
    "binary_y_train = binary_y_train.astype(float)\n",
    "\n",
    "# Convert all labels of 0 to -1 \n",
    "binary_y_train[binary_y_train == 0] = -1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
